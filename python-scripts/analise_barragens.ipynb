{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Contagem de pixels"
      ],
      "metadata": {
        "id": "P6EwS8X3x68T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "!pip install shapely\n",
        "!pip install pyproj"
      ],
      "metadata": {
        "id": "KshFYwxc6LPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QytSHixO6Fza"
      },
      "outputs": [],
      "source": [
        "import rasterio\n",
        "import os\n",
        "import pandas as pd\n",
        "from shapely.geometry import Polygon, mapping\n",
        "from rasterio.features import geometry_mask\n",
        "import numpy as np\n",
        "from pyproj import Transformer\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "import geopandas as gpd\n",
        "from scipy.stats import linregress\n",
        "from rasterio.plot import show\n",
        "from rasterio.mask import mask\n",
        "from glob import glob\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "g6gnyLCS6NGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "csv_paths = {\n",
        "    2017: '/content/drive/My Drive/SENTINEL_DATA/sentinel2/2017/output/contagem_pixels.csv',\n",
        "    2018: '/content/drive/My Drive/SENTINEL_DATA/sentinel2/2018/output/contagem_pixels.csv',\n",
        "    2019: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2019/output/contagem_pixels.csv',\n",
        "    2020: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2020/output/contagem_pixels.csv',\n",
        "    2021: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2021/output/contagem_pixels.csv',\n",
        "    2022: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2022/output/contagem_pixels.csv',\n",
        "    2023: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2023/output/contagem_pixels.csv',\n",
        "    2024: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2024/output/contagem_pixels.csv',\n",
        "    2025: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2025/output/contagem_pixels.csv'\n",
        "}\n",
        "\n",
        "output_folders = {\n",
        "    2017: '/content/drive/My Drive/SENTINEL_DATA/sentinel2/2017/output/',\n",
        "    2018: '/content/drive/My Drive/SENTINEL_DATA/sentinel2/2018/output/',\n",
        "    2019: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2019/output/',\n",
        "    2020: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2020/output/',\n",
        "    2021: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2021/output/',\n",
        "    2022: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2022/output/',\n",
        "    2023: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2023/output/',\n",
        "    2024: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2024/output/',\n",
        "    2025: '/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2025/output/',\n",
        "}"
      ],
      "metadata": {
        "id": "FVNg-BsMdkzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_pixels(path_tif):\n",
        "    with rasterio.open(path_tif) as img:\n",
        "        #print(img.crs)\n",
        "        data = img.read(1)\n",
        "        transform = img.transform\n",
        "        crs_img = img.crs  # sistema de coordenadas do .tif\n",
        "\n",
        "        # reprojeta de EPSG:4326 (lat/lon) para o crs do .tif\n",
        "        transformer = Transformer.from_crs(\"EPSG:4326\", crs_img, always_xy=True)\n",
        "\n",
        "        def reproject_polygon(coords):\n",
        "            return Polygon([transformer.transform(x, y) for x, y in coords])\n",
        "\n",
        "        # cordenadas provenientes do google earth engine\n",
        "        arvorezinha_coords = [\n",
        "            (-54.13341114332514, -31.23703975708336),\n",
        "            (-54.12070820143061, -31.23703975708336),\n",
        "            (-54.12070820143061, -31.22081967345758),\n",
        "            (-54.13341114332514, -31.22081967345758)\n",
        "        ]\n",
        "\n",
        "        sanga_rasa_coords = [\n",
        "            (-54.124553222478525, -31.268190891664986),\n",
        "            (-54.10743000012745, -31.268190891664986),\n",
        "            (-54.10743000012745, -31.257992809414805),\n",
        "            (-54.124553222478525, -31.257992809414805)\n",
        "        ]\n",
        "\n",
        "        # reprojeta as coordenadas dos poligonos\n",
        "        arvorezinha_poly = reproject_polygon(arvorezinha_coords)\n",
        "        sanga_rasa_poly = reproject_polygon(sanga_rasa_coords)\n",
        "\n",
        "        # cria mascaras\n",
        "        mask1 = geometry_mask([mapping(arvorezinha_poly)], transform=transform, invert=True, out_shape=data.shape)\n",
        "        mask2 = geometry_mask([mapping(sanga_rasa_poly)], transform=transform, invert=True, out_shape=data.shape)\n",
        "\n",
        "        # 1 na watnet conta agua e 0 na unet (data == 1)\n",
        "        # 0 na watnet conta terra e 1 na unet\n",
        "        arvorezinha_count = np.sum((data == 1) & mask1)\n",
        "        sanga_rasa_count = np.sum((data == 1) & mask2)\n",
        "\n",
        "        return arvorezinha_count, sanga_rasa_count"
      ],
      "metadata": {
        "id": "FrmYexoh6OKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_pixels_aux(img_path):\n",
        "  result = []\n",
        "\n",
        "  # itera arquivos .tif\n",
        "  for arq in sorted(os.listdir(img_path)):\n",
        "      if arq.endswith(\".tif\"):\n",
        "          path = os.path.join(img_path, arq)\n",
        "          data_str = os.path.splitext(arq)[0]  # remove \".tif\" para pegar a data\n",
        "          try:\n",
        "              arvorezinha, sanga_rasa = count_pixels(path)\n",
        "              result.append({\"data\": data_str, \"Arvorezinha\": arvorezinha, \"Sanga_Rasa\": sanga_rasa})\n",
        "          except Exception as e:\n",
        "              print(f\"Erro ao processar {arq}: {e}\")\n",
        "\n",
        "  # cria o DataFrame e salva em .csv\n",
        "  df = pd.DataFrame(result)\n",
        "\n",
        "  output_path = os.path.join(img_path, \"contagem_pixels.csv\")\n",
        "  df.to_csv(output_path, index=False)"
      ],
      "metadata": {
        "id": "1II1-os_6R7m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_pixels_aux(output_folders[2017])\n",
        "count_pixels_aux(output_folders[2018])"
      ],
      "metadata": {
        "id": "pep3xjBmoGnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_pixels_aux(output_folders[2019])\n",
        "count_pixels_aux(output_folders[2020])\n",
        "count_pixels_aux(output_folders[2021])\n",
        "count_pixels_aux(output_folders[2022])\n",
        "count_pixels_aux(output_folders[2023])\n",
        "count_pixels_aux(output_folders[2024])\n",
        "count_pixels_aux(output_folders[2025])"
      ],
      "metadata": {
        "id": "Av5uIVw3p313"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_areas(img_path):\n",
        "    # coordenadas originais (EPSG:4326)\n",
        "    arvorezinha_coords = [\n",
        "            (-54.13341114332514, -31.23703975708336),\n",
        "            (-54.12070820143061, -31.23703975708336),\n",
        "            (-54.12070820143061, -31.22081967345758),\n",
        "            (-54.13341114332514, -31.22081967345758)\n",
        "    ]\n",
        "\n",
        "    sanga_rasa_coords = [\n",
        "            (-54.124553222478525, -31.268190891664986),\n",
        "            (-54.10743000012745, -31.268190891664986),\n",
        "            (-54.10743000012745, -31.257992809414805),\n",
        "            (-54.124553222478525, -31.257992809414805)\n",
        "    ]\n",
        "\n",
        "    for arq in sorted(os.listdir(img_path)):\n",
        "        if arq.endswith(\".tif\"):\n",
        "            path = os.path.join(img_path, arq)\n",
        "            data_str = os.path.splitext(arq)[0]\n",
        "            try:\n",
        "                with rasterio.open(path) as img:\n",
        "                    data = img.read(1)\n",
        "                    crs_img = img.crs\n",
        "                    transform = img.transform\n",
        "\n",
        "                    transformer = Transformer.from_crs(\"EPSG:4326\", crs_img, always_xy=True)\n",
        "                    arvorezinha_poly = Polygon([transformer.transform(x, y) for x, y in arvorezinha_coords])\n",
        "                    sanga_rasa_poly = Polygon([transformer.transform(x, y) for x, y in sanga_rasa_coords])\n",
        "\n",
        "                    arvorezinha_gdf = gpd.GeoDataFrame(geometry=[arvorezinha_poly], crs=crs_img)\n",
        "                    sanga_rasa_gdf = gpd.GeoDataFrame(geometry=[sanga_rasa_poly], crs=crs_img)\n",
        "\n",
        "                    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "                    show(data, transform=transform, ax=ax, cmap='gray')\n",
        "                    arvorezinha_gdf.boundary.plot(ax=ax, color='blue', label='Arvorezinha')\n",
        "                    sanga_rasa_gdf.boundary.plot(ax=ax, color='green', label='Sanga Rasa')\n",
        "                    plt.title(f\"Áreas para contagem - Data: {data_str}\")\n",
        "                    plt.legend()\n",
        "                    plt.show()\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao processar {arq}: {e}\")"
      ],
      "metadata": {
        "id": "UoScq9eodMRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "show_areas(output_folders[2017])\n",
        "#show_areas(output_folders[2023])"
      ],
      "metadata": {
        "id": "lwufnGZidaiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Análise da contagem de pixels"
      ],
      "metadata": {
        "id": "Ioxm3vFmyDi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''''def plot_count_pixels(csv_file_path, year):\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "\n",
        "    # converte a coluna 'data' para datetime\n",
        "    df['data'] = pd.to_datetime(df['data'])\n",
        "    df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "    df[['Arvorezinha', 'Sanga_Rasa']] = df[['Arvorezinha', 'Sanga_Rasa']].apply(pd.to_numeric)\n",
        "\n",
        "    # interpolação pra grantir continuidade das linhas no grafico\n",
        "    df[['Arvorezinha', 'Sanga_Rasa']] = df[['Arvorezinha', 'Sanga_Rasa']].interpolate(method='linear')\n",
        "\n",
        "    df = df.sort_values('data')\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(df['data'], df['Arvorezinha'], marker='o', linestyle='-', label='Arvorezinha', color='green')\n",
        "    plt.plot(df['data'], df['Sanga_Rasa'], marker='s', linestyle='--', label='Sanga Rasa', color='blue')\n",
        "\n",
        "    # título e eixos\n",
        "    plt.title(f'Contagem de Pixels de Água ao Longo de {year}')\n",
        "    plt.xlabel('Data')\n",
        "    plt.ylabel('Contagem de Pixels (água)')\n",
        "\n",
        "    # grade e legenda\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
        "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()''''"
      ],
      "metadata": {
        "id": "kXUHIlq-pKwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_count_pixels(csv_file_path, year):\n",
        "    # tenta ler o arquivo, se não achar, avisa e para a execução da função\n",
        "    try:\n",
        "        # lê o csv, garantindo que a coluna 'data' seja lida como texto (string)\n",
        "        # isso resolve a ambiguidade entre os formatos YYYYMMDD e YYYY-MM-DD\n",
        "        df = pd.read_csv(csv_file_path, dtype={'data': str})\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ARQUIVO NÃO ENCONTRADO. Arquivo: {csv_file_path}\")\n",
        "        return\n",
        "\n",
        "    # troca os '?' por NaN, um valor que o pandas entende como ausente\n",
        "    df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "    # converte a coluna 'data' para datetime\n",
        "    # o pandas se vira pra converter os diferentes formatos de data que são texto\n",
        "    df['data'] = pd.to_datetime(df['data'])\n",
        "\n",
        "    # transforma as colunas de interesse em tipo numérico\n",
        "    # o 'coerce' força erros de conversão a virarem NaN, o que evita que o script quebre\n",
        "    df[['Arvorezinha', 'Sanga_Rasa']] = df[['Arvorezinha', 'Sanga_Rasa']].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    # interpola os valores ausentes pra linha do gráfico não ter falhas\n",
        "    df[['Arvorezinha', 'Sanga_Rasa']] = df[['Arvorezinha', 'Sanga_Rasa']].interpolate(method='linear')\n",
        "\n",
        "    # garante que as datas estejam em ordem cronológica\n",
        "    df = df.sort_values('data')\n",
        "\n",
        "    # aqui começa a criação do gráfico\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(df['data'], df['Arvorezinha'], marker='o', linestyle='-', label='Arvorezinha', color='green')\n",
        "    plt.plot(df['data'], df['Sanga_Rasa'], marker='s', linestyle='--', label='Sanga Rasa', color='blue')\n",
        "\n",
        "    # título e nome dos eixos\n",
        "    plt.title(f'Contagem de Pixels de Água ao Longo de {year}')\n",
        "    plt.xlabel('Data')\n",
        "    plt.ylabel('Contagem de Pixels (água)')\n",
        "\n",
        "    # grade e legenda pra ficar mais fácil de ler\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # ajusta como as datas são mostradas no eixo x (um marcador por mês)\n",
        "    plt.gca().xaxis.set_major_locator(mdates.MonthLocator())\n",
        "    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
        "\n",
        "    # gira os nomes das datas pra não ficarem sobrepostos\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout() # ajusta o gráfico pra tudo caber na imagem\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "XBrtuA_1Uks4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_count_pixels(csv_paths[2017], '2017')"
      ],
      "metadata": {
        "id": "Gc6-NCLQ2h-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_count_pixels(csv_paths[2018], '2018')"
      ],
      "metadata": {
        "id": "-1MjhCVNwzPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_count_pixels(csv_paths[2019], '2019')"
      ],
      "metadata": {
        "id": "wKCGW4FQw13-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_count_pixels(csv_paths[2020], '2020')"
      ],
      "metadata": {
        "id": "Z_c1uXVqw38B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_count_pixels(csv_paths[2021], '2021')"
      ],
      "metadata": {
        "id": "mU67ZVtiw51K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_count_pixels(csv_paths[2022], '2022')"
      ],
      "metadata": {
        "id": "7oyounkgw7sS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_count_pixels(csv_paths[2023], '2023')"
      ],
      "metadata": {
        "id": "G0wwHaoOw9D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_count_pixels(csv_paths[2024], '2024')"
      ],
      "metadata": {
        "id": "wFckKYrvw-np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_count_pixels(csv_paths[2025], '2025')"
      ],
      "metadata": {
        "id": "9lSzfRkUuxFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# listas para armazenar os dados processados de cada barragem\n",
        "arvorezinha_data = []\n",
        "sanga_rasa_data = []\n",
        "\n",
        "# processa cada arquivo csv listado em csv_paths\n",
        "for year, path in csv_paths.items():\n",
        "    # tenta ler o arquivo; se não encontrar, avisa e pula para o próximo ano\n",
        "    try:\n",
        "        # lê o csv, forçando a coluna 'data' a ser lida como texto (string)\n",
        "        # isso ajuda o pandas a entender melhor os formatos YYYYMMDD e YYYY-MM-DD\n",
        "        df = pd.read_csv(path, dtype={'data': str})\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ARQUIVO NÃO ENCONTRADO. Arquivo: {path}, pulando o ano {year}\")\n",
        "        continue # vai para a próxima iteração do loop\n",
        "\n",
        "    # substitui \"?\" por NaN (Not a Number) para o pandas lidar melhor com dados ausentes\n",
        "    df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "    # converte a coluna 'data' para o formato datetime\n",
        "    # o pandas é bom em adivinhar o formato correto quando a coluna é texto\n",
        "    df['data'] = pd.to_datetime(df['data']) # convertendo a coluna 'data' original\n",
        "\n",
        "    # converte colunas de contagem de pixels para tipo numérico\n",
        "    # 'errors='coerce'' faz com que qualquer valor não conversível vire NaN\n",
        "    df[['Arvorezinha', 'Sanga_Rasa']] = df[['Arvorezinha', 'Sanga_Rasa']].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "    # interpola valores NaN (ausentes) para garantir a continuidade dos dados\n",
        "    # isso ajuda a preencher \"buracos\" nas séries temporais de forma linear\n",
        "    df[['Arvorezinha', 'Sanga_Rasa']] = df[['Arvorezinha', 'Sanga_Rasa']].interpolate(method='linear')\n",
        "\n",
        "    # obtém o maior valor de pixel de água por barragem no ano\n",
        "    max_arvorezinha = df['Arvorezinha'].max()\n",
        "    max_sanga_rasa = df['Sanga_Rasa'].max()\n",
        "\n",
        "    # converte o valor de pixel em área (m² → km²)\n",
        "    # cada pixel representa 10m x 10m = 100 m². para km², dividimos por 1.000.000\n",
        "    area_arvorezinha = (max_arvorezinha * 100) / 1_000_000 if pd.notna(max_arvorezinha) else np.nan\n",
        "    area_sanga_rasa = (max_sanga_rasa * 100) / 1_000_000 if pd.notna(max_sanga_rasa) else np.nan\n",
        "\n",
        "    # armazena os dados calculados para o ano atual\n",
        "    arvorezinha_data.append({'year': year, 'area': area_arvorezinha})\n",
        "    sanga_rasa_data.append({'year': year, 'area': area_sanga_rasa})\n",
        "\n",
        "# cria dataframes para cada barragem a partir das listas populadas\n",
        "df_arvorezinha = pd.DataFrame(arvorezinha_data)\n",
        "df_sanga_rasa = pd.DataFrame(sanga_rasa_data)\n",
        "\n",
        "# função para plotar os gráficos de área ao longo dos anos\n",
        "def plot_water_area(df, title):\n",
        "    plt.figure(figsize=(12, 6)) # define o tamanho da figura do gráfico\n",
        "\n",
        "    # barras para mostrar a maior área de água registrada no ano\n",
        "    plt.bar(df['year'], df['area'], color='lightblue', label='maior área do ano')\n",
        "    # linha conectando os pontos anuais\n",
        "    plt.plot(df['year'], df['area'], marker='o', linestyle='-', color='blue', label='valores anuais')\n",
        "\n",
        "    # calcula a regressão linear para mostrar uma linha de tendência\n",
        "    # 'df.dropna(subset=['year', 'area'])' garante que não haja NaNs na regressão\n",
        "    df_cleaned = df.dropna(subset=['year', 'area'])\n",
        "    if len(df_cleaned) >= 2: # precisa de pelo menos 2 pontos para uma linha\n",
        "        slope, intercept, _, _, _ = linregress(df_cleaned['year'], df_cleaned['area'])\n",
        "        trend_line = slope * df_cleaned['year'] + intercept\n",
        "        plt.plot(df_cleaned['year'], trend_line, color='red', linestyle='--', label=f'tendência: y = {slope:.2f}x + {intercept:.2f}')\n",
        "    else:\n",
        "        print(f\"não há dados suficientes para calcular a linha de tendência para {title}\")\n",
        "\n",
        "\n",
        "    # título e nomes dos eixos, com um toque de estilo\n",
        "    plt.title(f'Maior área de água por ano - {title}', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Ano', fontsize=12)\n",
        "    plt.ylabel('Área (km²)', fontsize=12)\n",
        "    plt.xticks(df['year'].unique(), fontweight='bold') # garante que todos os anos sejam mostrados e em negrito\n",
        "    plt.yticks(fontweight='bold') # valores do eixo y em negrito\n",
        "\n",
        "    plt.grid(True) # adiciona uma grade pra facilitar a leitura\n",
        "    plt.legend() # mostra a legenda do gráfico\n",
        "    plt.tight_layout() # ajusta o layout pra tudo caber direitinho\n",
        "    plt.show() # exibe o gráfico\n",
        "\n",
        "# gera e exibe os gráficos para cada barragem\n",
        "plot_water_area(df_arvorezinha, 'Barragem Arvorezinha')\n",
        "plot_water_area(df_sanga_rasa, 'Barragem Sanga Rasa')"
      ],
      "metadata": {
        "id": "BiSL4cDXsfLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob"
      ],
      "metadata": {
        "id": "z7-9BRA98JV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# função para exibir as imagens .tif de uma pasta\n",
        "def plot_tif_subplots(folder_path, year):\n",
        "    # encontra todos os arquivos .tif\n",
        "    tif_files = sorted(glob(os.path.join(folder_path, '*.tif')))\n",
        "\n",
        "    if not tif_files:\n",
        "        print(f\"Nenhuma imagem .tif encontrada para o ano {year}\")\n",
        "        return\n",
        "\n",
        "    num_images = len(tif_files)\n",
        "    cols = 6\n",
        "    rows = (num_images + cols - 1) // cols\n",
        "\n",
        "    # cria a figura com subplots\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(16, 5 * rows))\n",
        "    axs = axs.flatten()\n",
        "\n",
        "    for i, tif_path in enumerate(tif_files):\n",
        "        with rasterio.open(tif_path) as src:\n",
        "            img = src.read(1)\n",
        "        axs[i].imshow(img, cmap='gray')\n",
        "        axs[i].set_title(os.path.basename(tif_path).replace('.tif', ''), fontsize=9)\n",
        "        axs[i].axis('off')\n",
        "\n",
        "    # desativa eixos de subplots vazios\n",
        "    for j in range(i + 1, len(axs)):\n",
        "        axs[j].axis('off')\n",
        "\n",
        "    fig.suptitle(f'Imagens da barragem em {year}', fontsize=16, fontweight='bold')\n",
        "    plt.subplots_adjust(wspace=0.1, hspace=0.4, top=0.97)\n",
        "    plt.show()\n",
        "\n",
        "# executa para cada pasta\n",
        "for year, folder in output_folders.items():\n",
        "    plot_tif_subplots(folder, year)"
      ],
      "metadata": {
        "id": "K1RBpLKq8OF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"def plot_rgb_classification_subplots(base_folder, output_folder, year):\n",
        "    # encontra todos os arquivos de classificação .tif no output\n",
        "    classification_files = sorted(glob(os.path.join(output_folder, '*.tif')))\n",
        "\n",
        "    if not classification_files:\n",
        "        print(f\"Nenhuma imagem de classificação encontrada para o ano {year}\")\n",
        "        return\n",
        "\n",
        "    num_images = len(classification_files)\n",
        "    cols = 2  # RGB + classificação lado a lado\n",
        "    rows = num_images\n",
        "\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(10, 4 * rows))\n",
        "    if rows == 1:\n",
        "        axs = np.expand_dims(axs, axis=0)  # garante que axs[i][j] funcione mesmo com 1 linha\n",
        "\n",
        "    for i, class_path in enumerate(classification_files):\n",
        "        date_str = os.path.basename(class_path).replace('.tif', '')\n",
        "\n",
        "        # monta caminhos para as bandas\n",
        "        band_paths = {\n",
        "            'B2': os.path.join(base_folder, f'Sentinel2_L2A_Harmonizado_Export_{date_str}_B2.tif'),\n",
        "            'B3': os.path.join(base_folder, f'Sentinel2_L2A_Harmonizado_Export_{date_str}_B3.tif'),\n",
        "            'B4': os.path.join(base_folder, f'Sentinel2_L2A_Harmonizado_Export_{date_str}_B4.tif')\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            # carrega as bandas\n",
        "            with rasterio.open(band_paths['B2']) as b2, \\\n",
        "                 rasterio.open(band_paths['B3']) as b3, \\\n",
        "                 rasterio.open(band_paths['B4']) as b4:\n",
        "                rgb = np.stack([b4.read(1), b3.read(1), b2.read(1)], axis=-1)\n",
        "\n",
        "                # normaliza para 0-1\n",
        "                rgb = rgb.astype(np.float32)\n",
        "                rgb_min, rgb_max = np.percentile(rgb, 2), np.percentile(rgb, 98)\n",
        "                rgb = np.clip((rgb - rgb_min) / (rgb_max - rgb_min), 0, 1)\n",
        "\n",
        "            # carrega a classificação\n",
        "            with rasterio.open(class_path) as src_class:\n",
        "                class_img = src_class.read(1)\n",
        "\n",
        "            # plota RGB\n",
        "            axs[i][0].imshow(rgb)\n",
        "            axs[i][0].set_title(f'{date_str} - RGB', fontsize=9)\n",
        "            axs[i][0].axis('off')\n",
        "\n",
        "            # plota classificação\n",
        "            axs[i][1].imshow(class_img, cmap='gray')\n",
        "            axs[i][1].set_title(f'{date_str} - Classificação', fontsize=9)\n",
        "            axs[i][1].axis('off')\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Erro ao processar {date_str}: {e}\")\n",
        "            axs[i][0].axis('off')\n",
        "            axs[i][1].axis('off')\n",
        "\n",
        "    fig.suptitle(f'Composição RGB e Classificação - Ano {year}', fontsize=16, fontweight='bold')\n",
        "    plt.subplots_adjust(wspace=0.1, hspace=0.3, top=0.94)\n",
        "    plt.show()\"\"\""
      ],
      "metadata": {
        "id": "UvrYADPqm3cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_rgb_classification_subplots(base_folder, output_folder, year,\n",
        "                                     red_band_index=3,\n",
        "                                     green_band_index=2,\n",
        "                                     blue_band_index=1):\n",
        "    \"\"\"\n",
        "    plota gráficos com imagens rgb e suas classificações, lado a lado.\n",
        "\n",
        "    lê as bandas rgb (vermelho, verde, azul) de um único arquivo .tif multibanda.\n",
        "\n",
        "    Args:\n",
        "        base_folder (str): pasta com os arquivos .tif multibanda (ex: imagens sentinel-2).\n",
        "                           os arquivos devem ter nomes como 'sentinel2_{identificador_da_data}.tif' (ex: 'sentinel2_20180103.tif').\n",
        "        output_folder (str): pasta com os arquivos .tif de classificação.\n",
        "                             o nome do arquivo de classificação (sem .tif, ex: '20180103') deve fornecer o {identificador_da_data}\n",
        "                             para encontrar o arquivo rgb correspondente.\n",
        "        year (int or str): ano para o título principal do gráfico.\n",
        "        red_band_index (int): índice da banda vermelha no arquivo multibanda (base 1).\n",
        "                              padrão 4 (ex: banda 4 sentinel-2).\n",
        "        green_band_index (int): índice da banda verde (padrão 3).\n",
        "        blue_band_index (int): índice da banda azul (padrão 2).\n",
        "    \"\"\"\n",
        "    # localiza os arquivos .tif de classificação na pasta de saída\n",
        "    classification_files = sorted(glob(os.path.join(output_folder, '*.tif')))\n",
        "\n",
        "    if not classification_files:\n",
        "        print(f\"nenhuma imagem de classificação encontrada para o ano {year} em '{output_folder}'\")\n",
        "        return\n",
        "\n",
        "    num_images = len(classification_files)\n",
        "    cols = 2  # rgb e classificação, lado a lado\n",
        "    rows = num_images\n",
        "\n",
        "    fig, axs = plt.subplots(rows, cols, figsize=(10, 5 * rows)) # ajuste na altura da linha para melhor visualização\n",
        "    if rows == 1:\n",
        "        axs = np.expand_dims(axs, axis=0)  # garante que axs[i][j] funcione com apenas uma linha de gráficos\n",
        "\n",
        "    for i, class_path in enumerate(classification_files):\n",
        "        # extrai o identificador do nome do arquivo de classification.\n",
        "        # este identificador deve corresponder à parte da data no nome do arquivo rgb (ex: '20180103').\n",
        "        date_identifier = os.path.basename(class_path).replace('.tif', '')\n",
        "\n",
        "        # monta o caminho pro arquivo .tif multibanda rgb\n",
        "        # o nome esperado para o arquivo rgb é 'sentinel2_{date_identifier}.tif'\n",
        "        multiband_rgb_path = os.path.join(base_folder, f'sentinel2_{date_identifier}.tif')\n",
        "\n",
        "        plot_title_identifier = date_identifier # para os títulos dos subplots\n",
        "\n",
        "        try:\n",
        "            if not os.path.exists(multiband_rgb_path):\n",
        "                print(f\"arquivo rgb multibanda não encontrado: {multiband_rgb_path} (identificador '{plot_title_identifier}')\")\n",
        "                axs[i][0].set_title(f'{plot_title_identifier} - RGB (Não encontrado)', fontsize=9)\n",
        "                axs[i][0].axis('off')\n",
        "                # tenta carregar e exibir a classificação mesmo sem a imagem rgb\n",
        "                if os.path.exists(class_path):\n",
        "                    with rasterio.open(class_path) as src_class:\n",
        "                        class_img = src_class.read(1)\n",
        "                    axs[i][1].imshow(class_img, cmap='gray')\n",
        "                    axs[i][1].set_title(f'{plot_title_identifier} - Classificação', fontsize=9)\n",
        "                else:\n",
        "                    axs[i][1].set_title(f'{plot_title_identifier} - Classificação (Não encontrada)', fontsize=9)\n",
        "                axs[i][1].axis('off')\n",
        "                continue\n",
        "\n",
        "            # lê as bandas r, g, b do arquivo multibanda\n",
        "            with rasterio.open(multiband_rgb_path) as src_rgb:\n",
        "                red_band = src_rgb.read(red_band_index)\n",
        "                green_band = src_rgb.read(green_band_index)\n",
        "                blue_band = src_rgb.read(blue_band_index)\n",
        "                # empilha as bandas para criar a imagem rgb (altura, largura, 3)\n",
        "                rgb_image = np.stack([red_band, green_band, blue_band], axis=-1)\n",
        "\n",
        "            # normaliza a imagem para exibição (valores entre 0 e 1)\n",
        "            rgb_display = rgb_image.astype(np.float32)\n",
        "\n",
        "            valid_pixels = rgb_display[np.isfinite(rgb_display)] # apenas pixels válidos (finitos)\n",
        "\n",
        "            if valid_pixels.size == 0: # se não houver pixels válidos\n",
        "                rgb_display.fill(0) # a imagem resultante é preta\n",
        "            else:\n",
        "                min_p = np.percentile(valid_pixels, 2)\n",
        "                max_p = np.percentile(valid_pixels, 98)\n",
        "\n",
        "                if max_p <= min_p: # caso os dados sejam constantes ou a faixa de percentil seja inválida\n",
        "                    if np.allclose(valid_pixels, 0): # se os valores forem próximos de zero\n",
        "                        rgb_display.fill(0) # a imagem é preta\n",
        "                    else: # se for constante e não zero\n",
        "                        rgb_display.fill(1.0) # a imagem é branca\n",
        "                                              # (alternativa: preencher com 0.5 para cinza)\n",
        "                else:\n",
        "                    # suprime avisos de divisão inválida durante a normalização\n",
        "                    with np.errstate(invalid='ignore', divide='ignore'):\n",
        "                        rgb_display = (rgb_display - min_p) / (max_p - min_p)\n",
        "\n",
        "            rgb_display = np.clip(rgb_display, 0, 1) # aplica clip para garantir valores no intervalo [0,1]\n",
        "            rgb_display[~np.isfinite(rgb_display)] = 0 # converte nans/infs restantes para preto (0)\n",
        "\n",
        "            # carrega a imagem da classificação\n",
        "            with rasterio.open(class_path) as src_class:\n",
        "                class_img = src_class.read(1)\n",
        "\n",
        "            # exibe a imagem rgb\n",
        "            axs[i][0].imshow(rgb_display)\n",
        "            axs[i][0].set_title(f'{plot_title_identifier} - RGB', fontsize=9)\n",
        "            axs[i][0].axis('off')\n",
        "\n",
        "            # exibe a imagem de classification\n",
        "            axs[i][1].imshow(class_img, cmap='gray') # cmap 'gray' é adequado para classificação monobanda\n",
        "            axs[i][1].set_title(f'{plot_title_identifier} - Classificação', fontsize=9)\n",
        "            axs[i][1].axis('off')\n",
        "\n",
        "        except FileNotFoundError: # se não achar o arquivo de classificação\n",
        "            print(f\"arquivo de CLASSIFICAÇÃO não encontrado: {class_path}\")\n",
        "            axs[i][0].set_title(f'{plot_title_identifier} - RGB (Erro)', fontsize=9)\n",
        "            axs[i][0].axis('off')\n",
        "            axs[i][1].set_title(f'{plot_title_identifier} - Classificação (Erro)', fontsize=9)\n",
        "            axs[i][1].axis('off')\n",
        "        except rasterio.errors.RasterioIOError as e: # erro específico do rasterio\n",
        "            print(f\"erro de rasterio i/o ao processar '{plot_title_identifier}' (RGB: {multiband_rgb_path}, Class: {class_path}): {e}\")\n",
        "            axs[i][0].set_title(f'{plot_title_identifier} - RGB (Erro I/O)', fontsize=9)\n",
        "            axs[i][0].axis('off')\n",
        "            axs[i][1].set_title(f'{plot_title_identifier} - Classificação (Erro I/O)', fontsize=9)\n",
        "            axs[i][1].axis('off')\n",
        "        except Exception as e: # tratamento para outros erros\n",
        "            print(f\"erro geral ao processar '{plot_title_identifier}': {e}\")\n",
        "            axs[i][0].set_title(f'{plot_title_identifier} - RGB (Erro Inesperado)', fontsize=9)\n",
        "            axs[i][0].axis('off')\n",
        "            axs[i][1].set_title(f'{plot_title_identifier} - Classificação (Erro Inesperado)', fontsize=9)\n",
        "            axs[i][1].axis('off')\n",
        "\n",
        "    fig.suptitle(f'Composição RGB e Classificação - Ano {year}', fontsize=16, fontweight='bold')\n",
        "    fig.tight_layout(rect=[0, 0.03, 1, 0.95]) # ajusta o layout para melhor encaixe, incluindo título principal\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "AF7Tq_r49-wK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_rgb_classification_subplots(\n",
        "    base_folder='/content/drive/My Drive/SENTINEL_DATA/sentinel2/2017/',\n",
        "    output_folder='/content/drive/My Drive/SENTINEL_DATA/sentinel2/2017/output/',\n",
        "    year=2017\n",
        ")"
      ],
      "metadata": {
        "id": "UQ5pGgR123iC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_rgb_classification_subplots(\n",
        "    base_folder='/content/drive/My Drive/SENTINEL_DATA/sentinel2/2018/',\n",
        "    output_folder='/content/drive/My Drive/SENTINEL_DATA/sentinel2/2018/output/',\n",
        "    year=2018\n",
        ")"
      ],
      "metadata": {
        "id": "komHSeId2xtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_rgb_classification_subplots(\n",
        "    base_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2019',\n",
        "    output_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2019/output',\n",
        "    year=2019\n",
        ")"
      ],
      "metadata": {
        "id": "YSjqYcEfcALJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_rgb_classification_subplots(\n",
        "    base_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2020',\n",
        "    output_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2020/output',\n",
        "    year=2020\n",
        ")"
      ],
      "metadata": {
        "id": "ngn4MgrWJzFH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_rgb_classification_subplots(\n",
        "    base_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2021',\n",
        "    output_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2021/output',\n",
        "    year=2021\n",
        ")"
      ],
      "metadata": {
        "id": "jD-DxsDem4RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_rgb_classification_subplots(\n",
        "    base_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2022',\n",
        "    output_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2022/output',\n",
        "    year=2022\n",
        ")"
      ],
      "metadata": {
        "id": "CwqCjC1UMVFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_rgb_classification_subplots(\n",
        "    base_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2023',\n",
        "    output_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2023/output',\n",
        "    year=2023\n",
        ")"
      ],
      "metadata": {
        "id": "h3anX7AdMXSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_rgb_classification_subplots(\n",
        "    base_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2024',\n",
        "    output_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2024/output',\n",
        "    year=2024\n",
        ")"
      ],
      "metadata": {
        "id": "fP3Rno32MZd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_rgb_classification_subplots(\n",
        "    base_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2025',\n",
        "    output_folder='/content/drive/My Drive/GEE_Folder_Raw_40_Perc_2025/output',\n",
        "    year=2025\n",
        ")"
      ],
      "metadata": {
        "id": "JiPq1a24Ma-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gif_generate(img_path):\n",
        "    df = pd.read_csv(os.path.join(img_path, \"contagem_pixels.csv\"))\n",
        "    df[\"data\"] = pd.to_datetime(df[\"data\"], errors=\"coerce\")\n",
        "\n",
        "    coords = {\n",
        "        \"Arvorezinha\": [\n",
        "            (-54.13341114332514, -31.23703975708336),\n",
        "            (-54.12070820143061, -31.23703975708336),\n",
        "            (-54.12070820143061, -31.22081967345758),\n",
        "            (-54.13341114332514, -31.22081967345758)\n",
        "        ],\n",
        "        \"Sanga_Rasa\": [\n",
        "            (-54.124553222478525, -31.268190891664986),\n",
        "            (-54.10743000012745, -31.268190891664986),\n",
        "            (-54.10743000012745, -31.257992809414805),\n",
        "            (-54.124553222478525, -31.257992809414805)\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    for barragem in [\"Arvorezinha\", \"Sanga_Rasa\"]:\n",
        "        imagens = []\n",
        "        grouped = df.groupby([df[\"data\"].dt.year, df[\"data\"].dt.month])\n",
        "        selecionadas = grouped.apply(lambda x: x.loc[x[barragem].idxmax()]).reset_index(drop=True)\n",
        "\n",
        "        for _, row in selecionadas.iterrows():\n",
        "            data_str = row[\"data\"].strftime(\"%Y-%m-%d\")\n",
        "            file_path = os.path.join(img_path, f\"{row['data'].strftime('%Y-%m-%d')}.tif\")\n",
        "\n",
        "            try:\n",
        "                with rasterio.open(file_path) as src:\n",
        "                    crs_img = src.crs\n",
        "                    transformer = Transformer.from_crs(\"EPSG:4326\", crs_img, always_xy=True)\n",
        "                    poly = Polygon([transformer.transform(x, y) for x, y in coords[barragem]])\n",
        "                    geojson = [mapping(poly)]\n",
        "\n",
        "                    cropped_image, cropped_transform = mask(src, geojson, crop=True)\n",
        "\n",
        "                    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "                    show(cropped_image[0], transform=cropped_transform, ax=ax, cmap=\"gray\")\n",
        "                    plt.title(f\"{barragem} - {data_str}\")\n",
        "                    plt.axis(\"off\")\n",
        "\n",
        "                    temp_img_path = os.path.join(img_path, f\"_temp_{barragem}_{data_str}.png\")\n",
        "                    plt.savefig(temp_img_path, bbox_inches=\"tight\", pad_inches=0)\n",
        "                    plt.close()\n",
        "                    imagens.append(Image.open(temp_img_path))\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Erro com {file_path}: {e}\")\n",
        "\n",
        "        if imagens:\n",
        "            gif_path = os.path.join(img_path, f\"{barragem}_max_por_mes.gif\")\n",
        "            imagens[0].save(gif_path, save_all=True, append_images=imagens[1:], duration=1000, loop=0)\n",
        "\n",
        "        for img in imagens:\n",
        "            img.close()\n",
        "        for arq in os.listdir(img_path):\n",
        "            if arq.startswith(\"_temp_\") and arq.endswith(\".png\"):\n",
        "                os.remove(os.path.join(img_path, arq))"
      ],
      "metadata": {
        "id": "jJONThywDQXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gif_generate(img_path):\n",
        "    # caminho completo para o arquivo de contagem de pixels\n",
        "    csv_file = os.path.join(img_path, \"contagem_pixels.csv\")\n",
        "\n",
        "    # tenta ler o csv, se não der certo, avisa e para\n",
        "    try:\n",
        "        # lê o csv, já falando pro pandas que a coluna 'data' é texto por enquanto\n",
        "        df = pd.read_csv(csv_file, dtype={'data': str})\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ops, não achei o csv aqui: {csv_file}\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"deu ruim ao ler o csv {csv_file}: {e}\")\n",
        "        return\n",
        "\n",
        "    # troca os \"?\" por NaN (not a number), que é como o pandas marca dados faltantes\n",
        "    df.replace(\"?\", np.nan, inplace=True)\n",
        "\n",
        "    # converte a coluna 'data' para o tipo datetime do pandas\n",
        "    # 'errors=\"coerce\"' faz com que datas inválidas virem NaT (not a time)\n",
        "    df[\"data\"] = pd.to_datetime(df[\"data\"], errors=\"coerce\")\n",
        "\n",
        "    # remove linhas onde a data não pôde ser convertida (virou NaT)\n",
        "    # isso é importante pra não tentar processar datas \"quebradas\" como 1970-01-01 por erro\n",
        "    df.dropna(subset=[\"data\"], inplace=True)\n",
        "    if df.empty:\n",
        "        print(f\"ih, depois de processar as datas, o arquivo {csv_file} ficou sem dados válidos.\")\n",
        "        return\n",
        "\n",
        "    # converte as colunas das barragens para número, se der erro vira NaN\n",
        "    for barragem_col in [\"Arvorezinha\", \"Sanga_Rasa\"]:\n",
        "        if barragem_col in df.columns:\n",
        "            df[barragem_col] = pd.to_numeric(df[barragem_col], errors='coerce')\n",
        "        else:\n",
        "            print(f\"aviso: coluna {barragem_col} não encontrada no csv {csv_file}\")\n",
        "\n",
        "\n",
        "    # coordenadas geográficas (latitude, longitude) das áreas de interesse (bounding box)\n",
        "    coords = {\n",
        "        \"Arvorezinha\": [\n",
        "            (-54.13341114332514, -31.23703975708336),\n",
        "            (-54.12070820143061, -31.23703975708336),\n",
        "            (-54.12070820143061, -31.22081967345758),\n",
        "            (-54.13341114332514, -31.22081967345758)\n",
        "        ],\n",
        "        \"Sanga_Rasa\": [\n",
        "            (-54.124553222478525, -31.268190891664986),\n",
        "            (-54.10743000012745, -31.268190891664986),\n",
        "            (-54.10743000012745, -31.257992809414805),\n",
        "            (-54.124553222478525, -31.257992809414805)\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # faz o processo para cada barragem\n",
        "    for barragem in [\"Arvorezinha\", \"Sanga_Rasa\"]:\n",
        "        if barragem not in df.columns: # se a coluna da barragem nem existe no csv\n",
        "            print(f\"pulando {barragem} pois a coluna não existe no csv.\")\n",
        "            continue\n",
        "\n",
        "        imagens = [] # lista para guardar os frames do gif\n",
        "        # agrupa os dados por ano e mês da coluna 'data'\n",
        "        grouped = df.groupby([df[\"data\"].dt.year, df[\"data\"].dt.month])\n",
        "\n",
        "        # funçãozinha pra pegar a linha com o maior valor da barragem dentro de cada grupo (mês/ano)\n",
        "        def get_row_with_max_value(x):\n",
        "            if x[barragem].notna().any(): # só tenta se tiver algum valor não-NaN na coluna da barragem\n",
        "                return x.loc[x[barragem].idxmax()]\n",
        "            return pd.Series(dtype='object') # senão, retorna uma linha vazia pra ser filtrada depois\n",
        "\n",
        "        # aplica a função e limpa as linhas que ficaram vazias (onde não tinha máximo)\n",
        "        selecionadas = grouped.apply(get_row_with_max_value).dropna(how='all').reset_index(drop=True)\n",
        "\n",
        "        if selecionadas.empty:\n",
        "            print(f\"não foram encontradas imagens/dados válidos para {barragem} após agrupar.\")\n",
        "            continue # pula pra próxima barragem se não sobrou nada\n",
        "\n",
        "        # para cada imagem selecionada (maior área do mês)\n",
        "        for _, row in selecionadas.iterrows():\n",
        "            data_obj = row[\"data\"] # é um objeto datetime aqui\n",
        "            # formato padrão para mostrar na tela e nos nomes temporários\n",
        "            display_date_str = data_obj.strftime(\"%Y-%m-%d\")\n",
        "\n",
        "            # formato 1: YYYY-MM-DD.tif\n",
        "            filename_hyphen = f\"{display_date_str}.tif\"\n",
        "            file_path_hyphen = os.path.join(img_path, filename_hyphen)\n",
        "\n",
        "            # formato 2: YYYYMMDD.tif\n",
        "            date_str_nodash = data_obj.strftime(\"%Y%m%d\")\n",
        "            filename_nodash = f\"{date_str_nodash}.tif\"\n",
        "            file_path_nodash = os.path.join(img_path, filename_nodash)\n",
        "\n",
        "            actual_file_path_to_use = None # guarda o caminho do arquivo que realmente existe\n",
        "\n",
        "            if os.path.exists(file_path_hyphen):\n",
        "                actual_file_path_to_use = file_path_hyphen\n",
        "            elif os.path.exists(file_path_nodash):\n",
        "                actual_file_path_to_use = file_path_nodash\n",
        "            else:\n",
        "                # se nenhum dos formatos existir, registra o problema e pula esta imagem\n",
        "                print(f\"ih, não achei o arquivo .tif para data {display_date_str} (busquei por '{filename_hyphen}' e '{filename_nodash}') em {img_path}\")\n",
        "                continue # pula para a próxima linha/imagem da tabela 'selecionadas'\n",
        "\n",
        "            try:\n",
        "                # tenta abrir a imagem raster (.tif) usando o caminho que encontramos\n",
        "                with rasterio.open(actual_file_path_to_use) as src:\n",
        "                    crs_img = src.crs # pega o sistema de coordenadas da imagem\n",
        "                    # prepara o transformador de coordenadas: de WGS84 (EPSG:4326) para o da imagem\n",
        "                    transformer = Transformer.from_crs(\"EPSG:4326\", crs_img, always_xy=True)\n",
        "                    # transforma as coordenadas do nosso polígono para o sistema da imagem\n",
        "                    poly_coords_transformed = [transformer.transform(x, y) for x, y in coords[barragem]]\n",
        "                    poly = Polygon(poly_coords_transformed)\n",
        "                    geojson = [mapping(poly)] # converte o polígono pra formato geojson\n",
        "\n",
        "                    # recorta a imagem raster usando o polígono (máscara)\n",
        "                    cropped_image, cropped_transform = mask(src, geojson, crop=True)\n",
        "\n",
        "                    # prepara a figura pra plotar a imagem recortada\n",
        "                    fig, ax = plt.subplots(figsize=(6, 6)) # tamanho da figura\n",
        "                    # mostra a primeira banda da imagem recortada (tons de cinza)\n",
        "                    show(cropped_image[0], transform=cropped_transform, ax=ax, cmap=\"gray\")\n",
        "                    plt.title(f\"{barragem} - {display_date_str}\") # título com nome da barragem e data (formato padrão)\n",
        "                    plt.axis(\"off\") # desliga os eixos pra ficar mais limpo\n",
        "\n",
        "                    # salva a imagem plotada como um png temporário (usa o formato de data padrão)\n",
        "                    temp_img_path = os.path.join(img_path, f\"_temp_{barragem}_{display_date_str}.png\")\n",
        "                    plt.savefig(temp_img_path, bbox_inches=\"tight\", pad_inches=0)\n",
        "                    plt.close(fig) # fecha a figura pra não consumir memória\n",
        "                    # abre o png salvo e adiciona na lista de imagens para o gif\n",
        "                    imagens.append(Image.open(temp_img_path))\n",
        "\n",
        "            except rasterio.errors.RasterioIOError:\n",
        "                # esse erro acontece se o arquivo existe mas não pode ser aberto\n",
        "                print(f\"xi, o arquivo {actual_file_path_to_use} existe, mas não consegui abrir.\")\n",
        "            except Exception as e:\n",
        "                print(f\"deu algum pepino com o arquivo {actual_file_path_to_use}: {e}\")\n",
        "\n",
        "        if imagens:\n",
        "            gif_path = os.path.join(img_path, f\"{barragem}_max_por_mes.gif\")\n",
        "            # salva o gif\n",
        "            imagens[0].save(gif_path, save_all=True, append_images=imagens[1:], duration=1000, loop=0)\n",
        "            print(f\"gif salvo para {barragem} em: {gif_path}\")\n",
        "        else:\n",
        "            print(f\"sem imagens pra criar o gif da barragem {barragem}.\")\n",
        "\n",
        "        # fecha os objetos de imagem abertos e apaga os pngs temporários\n",
        "        for img_obj in imagens:\n",
        "            img_obj.close() # fecha cada imagem da lista\n",
        "\n",
        "        for arq_temp in os.listdir(img_path):\n",
        "            # os arquivos temporários são salvos com o display_date_str (YYYY-MM-DD)\n",
        "            if arq_temp.startswith(f\"_temp_{barragem}_\") and arq_temp.endswith(\".png\"):\n",
        "                try:\n",
        "                    os.remove(os.path.join(img_path, arq_temp))\n",
        "                except Exception as e:\n",
        "                    print(f\"ops, não consegui apagar o arquivo temporário {arq_temp}: {e}\")"
      ],
      "metadata": {
        "id": "JcbYOLJib5ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gif_generate(output_folders[2017])\n",
        "gif_generate(output_folders[2018])"
      ],
      "metadata": {
        "id": "U9JBusepckHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gif_generate(output_folders[2019])\n",
        "gif_generate(output_folders[2020])\n",
        "gif_generate(output_folders[2021])\n",
        "gif_generate(output_folders[2022])\n",
        "gif_generate(output_folders[2023])\n",
        "gif_generate(output_folders[2024])\n",
        "gif_generate(output_folders[2025])"
      ],
      "metadata": {
        "id": "Zv7BP6LaDVbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image as IPyImage, display"
      ],
      "metadata": {
        "id": "W-0kBXdUK4Xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(IPyImage(filename=os.path.join(output_folders[2017], \"Arvorezinha_max_por_mes.gif\")))\n",
        "display(IPyImage(filename=os.path.join(output_folders[2017], \"Sanga_Rasa_max_por_mes.gif\")))"
      ],
      "metadata": {
        "id": "9Im3FkaTep3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(IPyImage(filename=os.path.join(output_folders[2018], \"Arvorezinha_max_por_mes.gif\")))\n",
        "display(IPyImage(filename=os.path.join(output_folders[2018], \"Sanga_Rasa_max_por_mes.gif\")))"
      ],
      "metadata": {
        "id": "qHxUnAU7ercT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(IPyImage(filename=os.path.join(output_folders[2019], \"Arvorezinha_max_por_mes.gif\")))\n",
        "display(IPyImage(filename=os.path.join(output_folders[2019], \"Sanga_Rasa_max_por_mes.gif\")))"
      ],
      "metadata": {
        "id": "BYA0vKiNK7Bs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(IPyImage(filename=os.path.join(output_folders[2020], \"Arvorezinha_max_por_mes.gif\")))\n",
        "display(IPyImage(filename=os.path.join(output_folders[2020], \"Sanga_Rasa_max_por_mes.gif\")))"
      ],
      "metadata": {
        "id": "7Pylo-4VLyr5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(IPyImage(filename=os.path.join(output_folders[2021], \"Arvorezinha_max_por_mes.gif\")))\n",
        "display(IPyImage(filename=os.path.join(output_folders[2021], \"Sanga_Rasa_max_por_mes.gif\")))"
      ],
      "metadata": {
        "id": "7dUQUo-VL0G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(IPyImage(filename=os.path.join(output_folders[2022], \"Arvorezinha_max_por_mes.gif\")))\n",
        "display(IPyImage(filename=os.path.join(output_folders[2022], \"Sanga_Rasa_max_por_mes.gif\")))"
      ],
      "metadata": {
        "id": "rzWheHPRL25N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(IPyImage(filename=os.path.join(output_folders[2023], \"Arvorezinha_max_por_mes.gif\")))\n",
        "display(IPyImage(filename=os.path.join(output_folders[2023], \"Sanga_Rasa_max_por_mes.gif\")))"
      ],
      "metadata": {
        "id": "2OgRKn74L44x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(IPyImage(filename=os.path.join(output_folders[2024], \"Arvorezinha_max_por_mes.gif\")))\n",
        "display(IPyImage(filename=os.path.join(output_folders[2024], \"Sanga_Rasa_max_por_mes.gif\")))"
      ],
      "metadata": {
        "id": "zysOaIgYL621"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(IPyImage(filename=os.path.join(output_folders[2025], \"Arvorezinha_max_por_mes.gif\")))\n",
        "display(IPyImage(filename=os.path.join(output_folders[2025], \"Sanga_Rasa_max_por_mes.gif\")))"
      ],
      "metadata": {
        "id": "3CCqfheGL8vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "C9zVknEsvu-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}